{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('../')\n",
    "import argparse\n",
    "import os\n",
    "from chemvae_torch import hyperparameters\n",
    "from chemvae import models\n",
    "from pathlib import Path\n",
    "import json\n",
    "import keras\n",
    "from keras import layers\n",
    "from chemvae.tgru_k2_gpu import TerminalGRU\n",
    "from keras.layers import GRU\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "from chemvae_torch.models_torch import (\n",
    "    EncoderModel, \n",
    "    DecoderModel, \n",
    "    PropertyPredictorModel, \n",
    "    CustomBatchNorm1d,\n",
    "    CustomGRU,\n",
    ")\n",
    "from chemvae.models import encoder_model, decoder_model\n",
    "from chemvae_torch import mol_utils as mu\n",
    "import yaml\n",
    "# from chemvae_torch.tgru_torch import CustomGRU\n",
    "import h5py\n",
    "import copy\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from chemvae_torch.utils_torch import smiles_to_hot, hot_to_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 1\n",
    "hidden_size = 35\n",
    "input_size = 196\n",
    "custom_gru = CustomGRU(input_size, hidden_size, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random input with size (1, 120, 196)\n",
    "input = torch.randn(10, 120, 196)\n",
    "target = torch.randn(10, 120, 35)\n",
    "\n",
    "x = custom_gru(input, targets=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Keras models (encoder, decoder and property predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load params\n",
    "\n",
    "params = hyperparameters.load_params(None)\n",
    "encoder_path = Path.cwd().parent / \"checkpoints/zinc_properties/zinc_encoder.h5\"\n",
    "decoder_path = Path.cwd().parent / \"checkpoints/zinc_properties/zinc_decoder.h5\"\n",
    "prop_pred_path = Path.cwd().parent / \"checkpoints/zinc_properties/zinc_prop_pred.h5\"\n",
    "print(\"All params:\", params)\n",
    "\n",
    "with open('../checkpoints/zinc_properties/exp.json') as json_file:\n",
    "    exp_params = json.load(json_file)\n",
    "params.update(exp_params)\n",
    "params[\"encoder_weights_file\"] = encoder_path\n",
    "params[\"decoder_weights_file\"] = decoder_path\n",
    "params[\"prop_pred_weights_file\"] = prop_pred_path\n",
    "params[\"reg_prop_tasks\"] = [\"qed\",\"SAS\",\"logP\"]\n",
    "params[\"NCHARS\"] = 35\n",
    "params[\"prop_hidden_dim\"] = 67\n",
    "params[\"prop_growth_factor\"] = 0.99028340731314179\n",
    "params[\"prop_pred_dropout\"] = 0.15694573998898703\n",
    "params[\"do_prop_pred\"] = True\n",
    "params[\"dropout_rate_mid\"] = 0\n",
    "params[\"do_tgru\"] = True\n",
    "\n",
    "params[\"char_file\"] = \"../checkpoints/zinc_properties/zinc.json\"\n",
    "chars = yaml.safe_load(open(params[\"char_file\"]))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# Load encoder model\n",
    "encoder = models.load_encoder(params)\n",
    "prop_pred = models.load_property_predictor(params)\n",
    "# decoder = models.load_decoder(params) >>>> Doesn't work. Inconsistent \"reset_after = True\" (GRU Layer)\n",
    "decoder = decoder_model(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hot_to_smiles(hot_x, indices_chars):\n",
    "    \n",
    "#     assert type(hot_x) == np.ndarray\n",
    "#     assert len(hot_x.shape) == 3\n",
    "    \n",
    "#     smiles = []\n",
    "#     for i in range(hot_x.shape[0]):  # number of samples\n",
    "#         temp_str = \"\"\n",
    "#         for j in range(hot_x.shape[1]):  # length of smiles\n",
    "#             index = np.argmax(hot_x[i, j, :])\n",
    "#             temp_str += indices_chars[index]\n",
    "#         smiles.append(temp_str)\n",
    "#     return smiles\n",
    "\n",
    "# def smiles_to_hot(smiles, params, canonize_smiles=True, check_smiles=False):\n",
    "#     if isinstance(smiles, str):\n",
    "#         smiles = [smiles]\n",
    "\n",
    "#     if canonize_smiles:\n",
    "#         smiles = [mu.canon_smiles(s) for s in smiles]\n",
    "\n",
    "#     if check_smiles:\n",
    "#         smiles = mu.smiles_to_hot_filter(smiles, char_indices)\n",
    "\n",
    "#     z = mu.smiles_to_hot(smiles, params[\"MAX_LEN\"], params[\"PADDING\"], char_indices, params[\"NCHARS\"])\n",
    "#     return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Decoder Weights from .h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading decoder weights from .h5 file (couldn't be retrieve through Keras)\n",
    "\n",
    "with h5py.File(Path.cwd().parent / 'checkpoints/zinc_properties/zinc_decoder.h5', 'r') as f:\n",
    "    groups = f[\"model_weights\"].keys()\n",
    "    # remove following keys from groups: \"decoder_input\", \"decoder_true_seq_input\", \"dropout_2\" and \"repeat_vector_1\".\n",
    "    groups = [group for group in groups if group not in [\"decoder_input\", \"decoder_true_seq_input\", \"dropout_2\", \"repeat_vector_1\"]]\n",
    "    # create a dictionary to store the weights\n",
    "    decoder_weights = {}\n",
    "    for group in groups:\n",
    "        layers = f[\"model_weights\"][group][group]\n",
    "        decoder_weights[group] = {}\n",
    "        for layer in layers:\n",
    "            decoder_weights[group][layer] = layers[layer][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_weights.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_weights['decoder_tgru'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_weights['decoder_tgru']['bias:0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_weights['decoder_tgru']['kernel:0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_weights['decoder_tgru']['recurrent_kernel:0'][:, :35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Torch encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiliazing Torch version of the model\n",
    "encoder_torch = EncoderModel(params)\n",
    "summary(encoder_torch, input_size=(120, 35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [weight.name for layer in encoder.layers for weight in layer.weights]\n",
    "weights = encoder.get_weights()\n",
    "\n",
    "for name, weight in zip(names, weights):\n",
    "    print(name, weight.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder: from Keras to Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gamma (Keras) <-> weight (PyTorch)\n",
    "# beta (Keras) <-> bias (PyTorch)\n",
    "# moving_mean (Keras) <-> running_mean (PyTorch)\n",
    "# moving_variance (Keras) <-> running_var (PyTorch)\n",
    "\n",
    "# Conv1D: .tranpose(2, 1, 0) because weights are stored in (kernel_size, input_channels, filters) format in Keras\n",
    "# versus (filters, input_channels, kernel_size) format in Pytorch\n",
    "\n",
    "# Conv 0\n",
    "encoder_torch.conv_layers[0].weight.data = torch.from_numpy(weights[0].transpose(2, 1, 0))  # T\n",
    "encoder_torch.conv_layers[0].bias.data = torch.from_numpy(weights[1])\n",
    "# BatchNorm 0\n",
    "encoder_torch.conv_norm_layers[0].weight.data = torch.from_numpy(weights[2]).view(1, -1)\n",
    "encoder_torch.conv_norm_layers[0].bias.data = torch.from_numpy(weights[3]).view(1, -1)\n",
    "encoder_torch.conv_norm_layers[0].running_mean.data = torch.from_numpy(weights[4]).view(1, -1)\n",
    "encoder_torch.conv_norm_layers[0].running_var.data = torch.from_numpy(weights[5]).view(1, -1)\n",
    "# Conv 1\n",
    "encoder_torch.conv_layers[1].weight.data = torch.from_numpy(weights[6].transpose(2, 1, 0))  # T\n",
    "encoder_torch.conv_layers[1].bias.data = torch.from_numpy(weights[7])\n",
    "# BatchNorm 1\n",
    "encoder_torch.conv_norm_layers[1].weight.data = torch.from_numpy(weights[8]).view(1, -1)\n",
    "encoder_torch.conv_norm_layers[1].bias.data = torch.from_numpy(weights[9]).view(1, -1)\n",
    "encoder_torch.conv_norm_layers[1].running_mean.data = torch.from_numpy(weights[10]).view(1, -1)\n",
    "encoder_torch.conv_norm_layers[1].running_var.data = torch.from_numpy(weights[11]).view(1, -1)\n",
    "# Conv 2\n",
    "encoder_torch.conv_layers[2].weight.data = torch.from_numpy(weights[12].transpose(2, 1, 0))  # T\n",
    "encoder_torch.conv_layers[2].bias.data = torch.from_numpy(weights[13])\n",
    "# BatchNorm 2\n",
    "encoder_torch.conv_norm_layers[2].weight.data = torch.from_numpy(weights[14]).view(1, -1)\n",
    "encoder_torch.conv_norm_layers[2].bias.data = torch.from_numpy(weights[15]).view(1, -1)\n",
    "encoder_torch.conv_norm_layers[2].running_mean.data = torch.from_numpy(weights[16]).view(1, -1)\n",
    "encoder_torch.conv_norm_layers[2].running_var.data = torch.from_numpy(weights[17]).view(1, -1)\n",
    "# Dense 0\n",
    "encoder_torch.middle_layers[0].weight.data = torch.from_numpy(weights[18].transpose(1, 0))\n",
    "encoder_torch.middle_layers[0].bias.data = torch.from_numpy(weights[19])\n",
    "# BatchNorm 3\n",
    "encoder_torch.middle_norm_layers[0].weight.data = torch.from_numpy(weights[20]).view(1, -1)\n",
    "encoder_torch.middle_norm_layers[0].bias.data = torch.from_numpy(weights[21]).view(1, -1)\n",
    "encoder_torch.middle_norm_layers[0].running_mean.data = torch.from_numpy(weights[22]).view(1, -1)\n",
    "encoder_torch.middle_norm_layers[0].running_var.data = torch.from_numpy(weights[23]).view(1, -1)\n",
    "# Dense 1\n",
    "encoder_torch.z_mean.weight.data = torch.from_numpy(weights[24].transpose(1, 0))\n",
    "encoder_torch.z_mean.bias.data = torch.from_numpy(weights[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.from_numpy(weights[0].transpose(2, 1, 0)).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Torch Property Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras model summary\n",
    "prop_pred.summary()\n",
    "\n",
    "# Print Keras layers\n",
    "names = [weight.name for layer in prop_pred.layers for weight in layer.weights]\n",
    "predictor_weights = prop_pred.get_weights()\n",
    "\n",
    "for name, weight in zip(names, predictor_weights):\n",
    "    print(name, weight.shape)\n",
    "\n",
    "# Initialize Torch model\n",
    "predictor_torch = PropertyPredictorModel(params)\n",
    "summary(predictor_torch, input_size=(196,))\n",
    "\n",
    "# Loading Keras weights into PyTorch model\n",
    "\n",
    "# Linear-1\n",
    "predictor_torch.ls_in.weight.data = torch.from_numpy(predictor_weights[0].transpose())\n",
    "predictor_torch.ls_in.bias.data = torch.from_numpy(predictor_weights[1])\n",
    "# Linear-3\n",
    "predictor_torch.hidden_layers[0].weight.data = torch.from_numpy(predictor_weights[2].transpose())\n",
    "predictor_torch.hidden_layers[0].bias.data = torch.from_numpy(predictor_weights[3])\n",
    "# BatchNorm1d-5\n",
    "predictor_torch.hidden_layers[2].weight.data = torch.from_numpy(predictor_weights[4]).view(1, -1)\n",
    "predictor_torch.hidden_layers[2].bias.data = torch.from_numpy(predictor_weights[5]).view(1, -1)\n",
    "predictor_torch.hidden_layers[2].running_mean.data = torch.from_numpy(predictor_weights[6]).view(1, -1)\n",
    "predictor_torch.hidden_layers[2].running_var.data = torch.from_numpy(predictor_weights[7]).view(1, -1)\n",
    "# Linear-6\n",
    "predictor_torch.hidden_layers[3].weight.data = torch.from_numpy(predictor_weights[8].transpose())\n",
    "predictor_torch.hidden_layers[3].bias.data = torch.from_numpy(predictor_weights[9])\n",
    "# BatchNorm1d-8\n",
    "predictor_torch.hidden_layers[5].weight.data = torch.from_numpy(predictor_weights[10]).view(1, -1)\n",
    "predictor_torch.hidden_layers[5].bias.data = torch.from_numpy(predictor_weights[11]).view(1, -1)\n",
    "predictor_torch.hidden_layers[5].running_mean.data = torch.from_numpy(predictor_weights[12]).view(1, -1)\n",
    "predictor_torch.hidden_layers[5].running_var.data = torch.from_numpy(predictor_weights[13]).view(1, -1)\n",
    "# Linear-9\n",
    "predictor_torch.reg_prop_pred.weight.data = torch.from_numpy(predictor_weights[14].transpose())\n",
    "predictor_torch.reg_prop_pred.bias.data = torch.from_numpy(predictor_weights[15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Torch decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiliazing Torch version of the decoder model\n",
    "decoder_torch = DecoderModel(params)\n",
    "decoder_torch.eval()\n",
    "# summary(decoder_torch, input_size=(196,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder: loading .h5 weights in torch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to invert the order of update and reset weights, and transspose the weights\n",
    "# Keras: update (z), reset (r), new (n)\n",
    "# PyTorch: reset (r), update (z), new (n)\n",
    "\n",
    "def weights_keras_to_torch(weights):\n",
    "    input_dim = weights.shape[1] // 3\n",
    "    if weights.shape[1] % 3 != 0:\n",
    "        raise ValueError(\"Input dimension must be divisible by 3\")\n",
    "    weights_torch = np.zeros(weights.shape)\n",
    "    # loading reset weights\n",
    "    weights_torch[:, :input_dim] = weights[:, input_dim:2 * input_dim]\n",
    "    # loading update weights\n",
    "    weights_torch[:, input_dim:2 * input_dim] = weights[:, :input_dim]\n",
    "    # loading new weights\n",
    "    weights_torch[:, 2 * input_dim:] = weights[:, 2 * input_dim:]\n",
    "    weights_torch = weights_torch.transpose(1, 0)\n",
    "    weights_torch = torch.from_numpy(weights_torch)\n",
    "    return weights_torch\n",
    "\n",
    "def bias_keras_to_torch(bias):\n",
    "    input_dim = bias.shape[0] // 3\n",
    "    if bias.shape[0] % 3 != 0:\n",
    "        raise ValueError(\"Input dimension must be divisible by 3\")\n",
    "    bias_torch = np.zeros(bias.shape)\n",
    "    # loading reset weights\n",
    "    bias_torch[:input_dim] = bias[input_dim:2 * input_dim]\n",
    "    # loading update weights\n",
    "    bias_torch[input_dim:2 * input_dim] = bias[:input_dim]\n",
    "    # loading new weights\n",
    "    bias_torch[2 * input_dim:] = bias[2 * input_dim:]\n",
    "    bias_torch = torch.from_numpy(bias_torch)\n",
    "    return bias_torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiating different decoder versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder_dense0\n",
    "decoder_torch.z[0].weight.data = torch.from_numpy(decoder_weights[\"decoder_dense0\"]['kernel:0'].transpose())\n",
    "decoder_torch.z[0].bias.data = torch.from_numpy(decoder_weights[\"decoder_dense0\"]['bias:0'])\n",
    "# batchnorm\n",
    "decoder_torch.z[2].weight.data = torch.from_numpy(decoder_weights[\"decoder_dense0_norm\"][\"gamma:0\"]).view(1, -1)\n",
    "decoder_torch.z[2].bias.data = torch.from_numpy(decoder_weights[\"decoder_dense0_norm\"][\"beta:0\"]).view(1, -1)\n",
    "decoder_torch.z[2].running_mean.data = torch.from_numpy(decoder_weights[\"decoder_dense0_norm\"][\"moving_mean:0\"]).view(1, -1)\n",
    "decoder_torch.z[2].running_var.data = torch.from_numpy(decoder_weights[\"decoder_dense0_norm\"][\"moving_variance:0\"]).view(1, -1)\n",
    "\n",
    "# Regarding the biases of GRU gates:\n",
    "\n",
    "# This is what the computation should looks like:\n",
    "# update_gate = torch.sigmoid(torch.matmul(input, z_weights_ih) + torch.matmul(hidden_state, z_weights_hh) + z_bias_ih + z_bias_hh)\n",
    "# reset_gate = torch.sigmoid(torch.matmul(input, r_weights_ih) + torch.matmul(hidden_state, r_weights_hh) + r_bias_ih + r_bias_hh)\n",
    "# new_memory_content = torch.tanh(torch.matmul(input, n_weights_ih) + torch.matmul(reset_gate * hidden_state, n_weights_hh) + n_bias_ih + n_bias_hh)\n",
    "\n",
    "# We can see that it doesn't matter whether we use z_bias_ih or z_bias_hh, since they are added together.\n",
    "# In Pytorch, we can't remove the recurrent bias (which is what Keras does when reset_after=False). \n",
    "# Since the model trained by the ChemVAE team had reset_after=False, we only have the input bias. \n",
    "# Therefore, we can set the recurrent bias to 0.\n",
    "\n",
    "# GRU 0\n",
    "decoder_torch.x_dec[0].weight_ih_l0.data = weights_keras_to_torch(decoder_weights['decoder_gru0'][\"kernel:0\"])  # input kernel\n",
    "decoder_torch.x_dec[0].weight_hh_l0.data = weights_keras_to_torch(decoder_weights['decoder_gru0'][\"recurrent_kernel:0\"])  # recurrent kernel\n",
    "decoder_torch.x_dec[0].bias_ih_l0.data = bias_keras_to_torch(decoder_weights['decoder_gru0'][\"bias:0\"])\n",
    "bias_0 = np.zeros_like(decoder_weights['decoder_gru0'][\"bias:0\"])\n",
    "decoder_torch.x_dec[0].bias_hh_l0.data = bias_keras_to_torch(bias_0) # bias -> which one to keep?\n",
    "\n",
    "# GRU 1\n",
    "decoder_torch.x_dec[1].weight_ih_l0.data = weights_keras_to_torch(decoder_weights['decoder_gru1'][\"kernel:0\"])  # input kernel\n",
    "decoder_torch.x_dec[1].weight_hh_l0.data = weights_keras_to_torch(decoder_weights['decoder_gru1'][\"recurrent_kernel:0\"])  # recurrent kernel\n",
    "decoder_torch.x_dec[1].bias_ih_l0.data = bias_keras_to_torch(decoder_weights['decoder_gru1'][\"bias:0\"])\n",
    "bias_0 = np.zeros_like(decoder_weights['decoder_gru1'][\"bias:0\"])\n",
    "decoder_torch.x_dec[1].bias_hh_l0.data = bias_keras_to_torch(bias_0) # bias -> which one to keep?\n",
    "\n",
    "# GRU 2\n",
    "decoder_torch.x_dec[2].weight_ih_l0.data = weights_keras_to_torch(decoder_weights['decoder_gru2'][\"kernel:0\"])  # input kernel\n",
    "decoder_torch.x_dec[2].weight_hh_l0.data = weights_keras_to_torch(decoder_weights['decoder_gru2'][\"recurrent_kernel:0\"])  # recurrent kernel\n",
    "decoder_torch.x_dec[2].bias_ih_l0.data = bias_keras_to_torch(decoder_weights['decoder_gru2'][\"bias:0\"])\n",
    "bias_0 = np.zeros_like(decoder_weights['decoder_gru2'][\"bias:0\"])\n",
    "decoder_torch.x_dec[2].bias_hh_l0.data = bias_keras_to_torch(bias_0) # bias -> which one to keep?\n",
    "\n",
    "# GRU 3\n",
    "# Removing kernels from teacher forcing\n",
    "# (35, 140) --> [:, update_gate:reset_gate:new_gate:teacher_forcing]\n",
    "\n",
    "# Remark:\n",
    "# The original code suggests that no bias was applied at the candidate hidden state computation.\n",
    "\n",
    "# VERSION 1:\n",
    "recurrent_kernel_final = np.concatenate((decoder_weights['decoder_tgru'][\"recurrent_kernel:0\"][:, :35], \n",
    "                                        decoder_weights['decoder_tgru'][\"recurrent_kernel:0\"][:, 70:]), axis=1)\n",
    "# recurrent_kernel_final = decoder_weights['decoder_tgru'][\"recurrent_kernel:0\"][:, :105]\n",
    "# bias_final = np.concatenate((decoder_weights['decoder_tgru'][\"bias:0\"][:70], decoder_weights['decoder_tgru'][\"bias:0\"][105:]), axis=0)\n",
    "bias_final = np.concatenate((decoder_weights['decoder_tgru'][\"bias:0\"][:35], \n",
    "                            decoder_weights['decoder_tgru'][\"bias:0\"][70:]), axis=0)\n",
    "\n",
    "decoder_torch.x_out.cell.weight_ih.data = weights_keras_to_torch(decoder_weights['decoder_tgru'][\"kernel:0\"])  # input kernel\n",
    "decoder_torch.x_out.cell.weight_hh.data = weights_keras_to_torch(recurrent_kernel_final)  # recurrent kernel\n",
    "decoder_torch.x_out.cell.bias_ih.data = bias_keras_to_torch(bias_final)\n",
    "# bias_final_0 = np.zeros_like(bias_final)\n",
    "# bias_final_0[70:] = decoder_weights['decoder_tgru'][\"bias:0\"][105:]\n",
    "# decoder_torch.x_out.cell.bias_hh.data = bias_keras_to_torch(bias_final_0) # bias -> which one to keep?\n",
    "\n",
    "# # VERSION 2:\n",
    "decoder_torch_2 = copy.deepcopy(decoder_torch)\n",
    "recurrent_kernel_final = decoder_weights['decoder_tgru'][\"recurrent_kernel:0\"][:, :105]\n",
    "bias_final = decoder_weights['decoder_tgru'][\"bias:0\"][:105]\n",
    "decoder_torch_2.x_out.cell.weight_ih.data = weights_keras_to_torch(decoder_weights['decoder_tgru'][\"kernel:0\"])  # input kernel\n",
    "decoder_torch_2.x_out.cell.weight_hh.data = weights_keras_to_torch(recurrent_kernel_final)  # recurrent kernel\n",
    "decoder_torch_2.x_out.cell.bias_ih.data = bias_keras_to_torch(bias_final)\n",
    "bias_final_0 = np.zeros_like(bias_final)\n",
    "decoder_torch_2.x_out.cell.bias_hh.data = bias_keras_to_torch(bias_final_0) # bias -> which one to keep?\n",
    "\n",
    "\n",
    "# # VERSION 3:\n",
    "decoder_torch_3 = copy.deepcopy(decoder_torch)\n",
    "recurrent_kernel_final = decoder_weights['decoder_tgru'][\"recurrent_kernel:0\"][:, :105]\n",
    "bias_final = np.concatenate((decoder_weights['decoder_tgru'][\"bias:0\"][:70], decoder_weights['decoder_tgru'][\"bias:0\"][105:]), axis=0)\n",
    "decoder_torch_3.x_out.cell.weight_ih.data = weights_keras_to_torch(decoder_weights['decoder_tgru'][\"kernel:0\"])  # input kernel\n",
    "decoder_torch_3.x_out.cell.weight_hh.data = weights_keras_to_torch(recurrent_kernel_final)  # recurrent kernel\n",
    "decoder_torch_3.x_out.cell.bias_ih.data = bias_keras_to_torch(bias_final)\n",
    "bias_final_0 = np.zeros_like(bias_final)\n",
    "decoder_torch_3.x_out.cell.bias_hh.data = bias_keras_to_torch(bias_final_0) # bias -> which one to keep?\n",
    "\n",
    "# # VERSION 4:\n",
    "decoder_torch_4 = copy.deepcopy(decoder_torch)\n",
    "recurrent_kernel_final = np.concatenate((decoder_weights['decoder_tgru'][\"recurrent_kernel:0\"][:, :70], \n",
    "                                        decoder_weights['decoder_tgru'][\"recurrent_kernel:0\"][:, 105:]), axis=1)\n",
    "bias_final = decoder_weights['decoder_tgru'][\"bias:0\"][:105] #, decoder_weights['decoder_tgru'][\"bias:0\"][105:]), axis=0)\n",
    "decoder_torch_4.x_out.cell.weight_ih.data = weights_keras_to_torch(decoder_weights['decoder_tgru'][\"kernel:0\"])  # input kernel\n",
    "decoder_torch_4.x_out.cell.weight_hh.data = weights_keras_to_torch(recurrent_kernel_final)  # recurrent kernel\n",
    "decoder_torch_4.x_out.cell.bias_ih.data = bias_keras_to_torch(bias_final)\n",
    "bias_final_0 = np.zeros_like(bias_final)\n",
    "decoder_torch_4.x_out.cell.bias_hh.data = bias_keras_to_torch(bias_final_0) # bias -> which one to keep?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking Autoencoder (Torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_1 = mu.canon_smiles('CSCC(=O)NNC(=O)c1c(C)oc(C)c1C')\n",
    "# smiles_1 = 'CSCC(=O)NNC(=O)c1c(C)oc(C)c1C'\n",
    "\n",
    "encoder_torch.to(torch.float32)\n",
    "\n",
    "decoder_torch.to(torch.float32)\n",
    "decoder_torch_2.to(torch.float32)\n",
    "decoder_torch_3.to(torch.float32)\n",
    "decoder_torch_4.to(torch.float32)\n",
    "\n",
    "encoder_torch.eval()\n",
    "\n",
    "decoder_torch.eval()\n",
    "decoder_torch_2.eval()\n",
    "decoder_torch_3.eval()\n",
    "decoder_torch_4.eval()\n",
    "\n",
    "input_onehot = smiles_to_hot(smiles_1, params, canonize_smiles=True)\n",
    "# input_onehot = input_onehot.transpose(0, 2, 1)\n",
    "input_onehot = torch.from_numpy(input_onehot).float()\n",
    "\n",
    "# encoding - decoding\n",
    "# the encoder returns the mean + the encoder output (which is an intermediary \n",
    "# used to derive the mean and the variance, and should not be used for inference!)\n",
    "z_mean, encoder_output = encoder_torch(input_onehot)\n",
    "output_onehot = decoder_torch(z_mean)\n",
    "output_onehot_2 = decoder_torch_2(z_mean)\n",
    "output_onehot_3 = decoder_torch_3(z_mean)\n",
    "output_onehot_4 = decoder_torch_4(z_mean)\n",
    "\n",
    "output_onehot = output_onehot.detach().numpy()\n",
    "output_onehot_2 = output_onehot_2.detach().numpy()\n",
    "output_onehot_3 = output_onehot_3.detach().numpy()\n",
    "output_onehot_4 = output_onehot_4.detach().numpy()\n",
    "\n",
    "z_mean = z_mean.detach().numpy()\n",
    "\n",
    "print('{:20s} : {}'.format('Input', smiles_1))\n",
    "print('{:20s} : {}'.format('Reconstruction 1', hot_to_smiles(output_onehot, indices_char)[0]))\n",
    "print('{:20s} : {}'.format('Reconstruction 2', hot_to_smiles(output_onehot_2, indices_char)[0]))\n",
    "print('{:20s} : {}'.format('Reconstruction 3', hot_to_smiles(output_onehot_3, indices_char)[0]))\n",
    "print('{:20s} : {}'.format('Reconstruction 4', hot_to_smiles(output_onehot_4, indices_char)[0]))\n",
    "print('{:20s} : {} with norm {:.3f}'.format('Z representation', z_mean.shape, np.linalg.norm(z_mean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the absolute path of the notebook\n",
    "# notebook_path = Path(__file__).resolve().parent\n",
    "path_to_data = Path(\"../exps/original\")\n",
    "\n",
    "# # saving the pretrained encoder model (original)\n",
    "# torch.save(encoder_torch.state_dict(), path_to_data / \"encoder.pt\")\n",
    "\n",
    "# # saving the pretrained decoder model (original)\n",
    "# torch.save(decoder_torch.state_dict(), path_to_data / \"decoder.pt\")\n",
    "\n",
    "# # saving the pretrained property prediction model (original)\n",
    "# torch.save(predictor_torch.state_dict(), path_to_data / \"prop_pred.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_test = EncoderModel(params)\n",
    "encoder_test.load_state_dict(torch.load(path_to_data / \"encoder.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_test = DecoderModel(params)\n",
    "decoder_test.load_state_dict(torch.load(path_to_data / \"decoder.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_test = PropertyPredictorModel(params)\n",
    "predictor_test.load_state_dict(torch.load(path_to_data / \"prop_pred.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in decoder_test.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment to identify best config between all transposes of matrices (kernel, recurrent_kernel)\n",
    "\n",
    "Results:      ker (0, 1, 2), rec (2, 1, 3, 0), bias (1, 0, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT WITH DIFFERENT PERMUTATIONS:\n",
    "recurrent_kernel_final = np.concatenate((decoder_weights['decoder_tgru'][\"recurrent_kernel:0\"][:, :35], \n",
    "                                        decoder_weights['decoder_tgru'][\"recurrent_kernel:0\"][:, 70:]), axis=1)\n",
    "bias_final = decoder_weights['decoder_tgru'][\"bias:0\"][:105]\n",
    "decoder_torch.x_out.cell.weight_ih.data = weights_keras_to_torch(decoder_weights['decoder_tgru'][\"kernel:0\"])  # input kernel\n",
    "decoder_torch.x_out.cell.weight_hh.data = weights_keras_to_torch(recurrent_kernel_final)  # recurrent kernel\n",
    "decoder_torch.x_out.cell.bias_ih.data = bias_keras_to_torch(bias_final)\n",
    "bias_final_0 = np.zeros_like(bias_final)\n",
    "bias_final_0[70:] = decoder_weights['decoder_tgru'][\"bias:0\"][105:]\n",
    "decoder_torch.x_out.cell.bias_hh.data = bias_keras_to_torch(bias_final_0) # bias -> which one to keep?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "\n",
    "# RECURRENT KERNEL\n",
    "# Define the elements\n",
    "elements = [0, 1, 2, 3]\n",
    "# Generate all permutations\n",
    "perms = permutations(elements)\n",
    "# Convert the permutations generator to a list\n",
    "perms_list = list(perms)\n",
    "\n",
    "# KERNEL\n",
    "# Define the elements\n",
    "elements_kernel = [0, 1, 2]\n",
    "# Generate all permutations\n",
    "perms_kernel = permutations(elements_kernel)\n",
    "# Convert the permutations generator to a list\n",
    "perms_kernel_list = list(perms_kernel)\n",
    "\n",
    "# preparing input\n",
    "smiles_1 = mu.canon_smiles('CSCC(=O)NNC(=O)c1c(C)oc(C)c1C')\n",
    "input_onehot = smiles_to_hot(smiles_1, params, canonize_smiles=True)\n",
    "input_onehot_numpy = np.copy(input_onehot)\n",
    "# input_onehot = input_onehot.transpose(0, 2, 1)\n",
    "input_onehot = torch.from_numpy(input_onehot).float()\n",
    "z_mean, encoder_output = encoder_torch(input_onehot)\n",
    "print('{:20s} : {}'.format('Input', smiles_1))\n",
    "\n",
    "best_score = 0\n",
    "best_config = dict()\n",
    "\n",
    "def compute_score(output, input_onehot):\n",
    "        score = np.sum(output_onehot * input_onehot)\n",
    "        return score\n",
    "\n",
    "for j, perm_kernel in enumerate(perms_kernel_list):\n",
    "        print(\"permutation kernel #{}\".format(j))\n",
    "        indices_kernel = list(np.arange(perm_kernel[0]*35, perm_kernel[0]*35 + 35)) \\\n",
    "                        + list(np.arange(perm_kernel[1]*35, perm_kernel[1]*35 + 35)) \\\n",
    "                        + list(np.arange(perm_kernel[2]*35, perm_kernel[2]*35 + 35))\n",
    "\n",
    "        for i, perm in enumerate(perms_list):\n",
    "                indices = list(np.arange(perm[0]*35, perm[0]*35 + 35)) \\\n",
    "                        + list(np.arange(perm[1]*35, perm[1]*35 + 35)) \\\n",
    "                        + list(np.arange(perm[2]*35, perm[2]*35 + 35))\n",
    "\n",
    "                for k, perm_bias in enumerate(perms_list):\n",
    "                        indices_bias = list(np.arange(perm_bias[0]*35, perm_bias[0]*35 + 35)) \\\n",
    "                                + list(np.arange(perm_bias[1]*35, perm_bias[1]*35 + 35)) \\\n",
    "                                + list(np.arange(perm_bias[2]*35, perm_bias[2]*35 + 35))\n",
    "                        \n",
    "                        kernel_final = decoder_weights['decoder_tgru'][\"kernel:0\"][:, indices_kernel]\n",
    "                        recurrent_kernel_final = decoder_weights['decoder_tgru'][\"recurrent_kernel:0\"][:, indices]\n",
    "                        bias_final = decoder_weights['decoder_tgru'][\"bias:0\"][indices_bias]\n",
    "\n",
    "                        decoder_torch.x_out.cell.weight_ih.data = weights_keras_to_torch(kernel_final)  # input kernel\n",
    "                        decoder_torch.x_out.cell.weight_hh.data = weights_keras_to_torch(recurrent_kernel_final)  # recurrent kernel\n",
    "                        decoder_torch.x_out.cell.bias_ih.data = bias_keras_to_torch(bias_final)\n",
    "                        \n",
    "                        decoder_torch.to(torch.float32)\n",
    "                        decoder_torch.eval()\n",
    "\n",
    "                        output = decoder_torch(z_mean)\n",
    "                        output = output.detach().numpy()\n",
    "                        \n",
    "                        output_smiles = hot_to_smiles(output, indices_char)[0]\n",
    "                        output_onehot = smiles_to_hot(output_smiles, params, canonize_smiles=False)\n",
    "\n",
    "                        score = compute_score(output_onehot, input_onehot_numpy)\n",
    "\n",
    "                        if score > best_score:\n",
    "                                best_score = score\n",
    "                                best_config[\"ker\"] = perm_kernel\n",
    "                                best_config[\"rec\"] = perm\n",
    "                                best_config[\"bias\"] = perm_bias\n",
    "\n",
    "                                best_output = output_smiles\n",
    "\n",
    "                        print('ker {}, rec {}, bias {}: {}'.format(perm_kernel, perm, perm_bias, hot_to_smiles(output, indices_char)[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best score:\", best_score)\n",
    "print(\"Best output: \", best_output)\n",
    "print(\"Best config: \", \"ker {}, rec {}, bias {}\".format(best_config[\"ker\"], best_config[\"rec\"], best_config[\"bias\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test best config:\n",
    "\n",
    "# perm_kernel = best_config[\"ker\"]\n",
    "# perm = best_config[\"rec\"]\n",
    "# perm_bias = best_config[\"bias\"]\n",
    "\n",
    "# indices_kernel = list(np.arange(perm_kernel[0]*35, perm_kernel[0]*35 + 35)) \\\n",
    "#                         + list(np.arange(perm_kernel[1]*35, perm_kernel[1]*35 + 35)) \\\n",
    "#                         + list(np.arange(perm_kernel[2]*35, perm_kernel[2]*35 + 35))\n",
    "\n",
    "# indices = list(np.arange(perm[0]*35, perm[0]*35 + 35)) \\\n",
    "#                         + list(np.arange(perm[1]*35, perm[1]*35 + 35)) \\\n",
    "#                         + list(np.arange(perm[2]*35, perm[2]*35 + 35))\n",
    "\n",
    "# indices_bias = list(np.arange(perm_bias[0]*35, perm_bias[0]*35 + 35)) \\\n",
    "#                         + list(np.arange(perm_bias[1]*35, perm_bias[1]*35 + 35)) \\\n",
    "#                         + list(np.arange(perm_bias[2]*35, perm_bias[2]*35 + 35))\n",
    "\n",
    "# kernel_final = decoder_weights['decoder_tgru'][\"kernel:0\"][:, indices_kernel]\n",
    "# recurrent_kernel_final = decoder_weights['decoder_tgru'][\"recurrent_kernel:0\"][:, indices]\n",
    "# bias_final = decoder_weights['decoder_tgru'][\"bias:0\"][indices_bias]\n",
    "\n",
    "# decoder_torch.x_out.cell.weight_ih.data = weights_keras_to_torch(kernel_final)  # input kernel\n",
    "# decoder_torch.x_out.cell.weight_hh.data = weights_keras_to_torch(recurrent_kernel_final)  # recurrent kernel\n",
    "# decoder_torch.x_out.cell.bias_ih.data = bias_keras_to_torch(bias_final)\n",
    "\n",
    "# decoder_torch.to(torch.float32)\n",
    "# decoder_torch.eval()\n",
    "\n",
    "# output_onehot = decoder_torch(z_mean)\n",
    "# output_onehot = output_onehot.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Property prediction (Torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = np.load(\"../checkpoints/zinc_properties/test_idx.npy\")\n",
    "df = pd.read_csv(\"../checkpoints/zinc_properties/250k_rndm_zinc_drugs_clean_3.csv\")\n",
    "\n",
    "df.head(10)\n",
    "\n",
    "df_test = df.iloc[test_idx]\n",
    "df_train = df.drop(test_idx)\n",
    "df_train_subset = df_train.iloc[:2_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = []\n",
    "\n",
    "encoder_torch.eval()\n",
    "predictor_torch.eval()\n",
    "\n",
    "for i in range(len(df_train_subset)):\n",
    "    smiles = df_train_subset.iloc[i][\"smiles\"]\n",
    "    input_onehot = smiles_to_hot(smiles, params, canonize_smiles=True)\n",
    "    # input_onehot = input_onehot.transpose(0, 2, 1)\n",
    "    input_onehot = torch.from_numpy(input_onehot).float()\n",
    "\n",
    "    # encoding - prediction\n",
    "    z_mean, encoder_output = encoder_torch(input_onehot)\n",
    "    properties = predictor_torch(z_mean)\n",
    "\n",
    "    preds_train.append(properties.detach().numpy())\n",
    "\n",
    "preds_train = [pred[:, np.newaxis] for pred in preds_train]\n",
    "preds_train = np.concatenate(preds_train, axis=1)[0]\n",
    "trues_train = df_train_subset[[\"qed\", \"SAS\", \"logP\"]].values\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "for i in range(3):\n",
    "    ax[i].scatter(trues_train[:, i], preds_train[:, i])\n",
    "    ax[i].set_xlabel(\"True\")\n",
    "    ax[i].set_ylabel(\"Predicted\")\n",
    "    ax[i].set_title(params[\"reg_prop_tasks\"][i])\n",
    "    # ensure y and x-axis limits are equal\n",
    "    ax[i].set_xlim(np.min(trues_train[:, i]) - 0.2, np.max(trues_train[:, i]) + 0.2)\n",
    "    ax[i].set_ylim(ax[i].get_xlim())\n",
    "    # add y=x line in red\n",
    "    ax[i].plot(np.linspace(ax[i].get_ylim()[0], ax[i].get_ylim()[1], 100), \n",
    "               np.linspace(ax[i].get_ylim()[0], ax[i].get_ylim()[1], 100), \"r-\", linewidth=2)\n",
    "    # adjust subplots\n",
    "fig.tight_layout()\n",
    "\n",
    "mae_qed = np.mean(np.abs(trues_train[:, 0] - preds_train[:, 0]))\n",
    "print(\"Mean Absolute Error (QED):\", mae_qed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax[0].get_ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "\n",
    "encoder_torch.eval()\n",
    "predictor_torch.eval()\n",
    "\n",
    "for i in range(len(df_test)):\n",
    "    smiles = df_test.iloc[i][\"smiles\"]\n",
    "    input_onehot = smiles_to_hot(smiles, params, canonize_smiles=True)\n",
    "    # input_onehot = input_onehot.transpose(0, 2, 1)\n",
    "    input_onehot = torch.from_numpy(input_onehot).float()\n",
    "\n",
    "    # encoding - prediction\n",
    "    z_mean, encoder_output = encoder_torch(input_onehot)\n",
    "    properties = predictor_torch(z_mean)\n",
    "\n",
    "    preds.append(properties.detach().numpy())\n",
    "\n",
    "preds = [pred[:, np.newaxis] for pred in preds]\n",
    "preds = np.concatenate(preds, axis=1)[0]\n",
    "trues = df_test[[\"qed\", \"SAS\", \"logP\"]].values\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "for i in range(3):\n",
    "    ax[i].scatter(trues[:, i], preds[:, i])\n",
    "    ax[i].set_xlabel(\"True\")\n",
    "    ax[i].set_ylabel(\"Predicted\")\n",
    "    ax[i].set_title(params[\"reg_prop_tasks\"][i])\n",
    "    # ensure y and x-axis limits are equal\n",
    "    ax[i].set_xlim(np.min(trues[:, i]) - 0.2, np.max(trues[:, i]) + 0.2)\n",
    "    ax[i].set_ylim(ax[i].get_xlim())\n",
    "    # add y=x line in red\n",
    "    ax[i].plot(np.linspace(ax[i].get_ylim()[0], ax[i].get_ylim()[1], 100), \n",
    "               np.linspace(ax[i].get_ylim()[0], ax[i].get_ylim()[1], 100), \"r-\", linewidth=2)\n",
    "    # adjust subplots\n",
    "fig.tight_layout()\n",
    "\n",
    "mae_qed = np.mean(np.abs(trues[:, 0] - preds[:, 0]))\n",
    "print(\"Mean Absolute Error (QED):\", mae_qed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions with Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "\n",
    "for i in range(len(df_test)):\n",
    "    smiles_1 = df_test.iloc[i][\"smiles\"]\n",
    "    X_1 = smiles_to_hot(smiles_1, params, canonize_smiles=True)\n",
    "\n",
    "    # encoding - prediction\n",
    "    z_mean, enc_output = encoder(X_1)\n",
    "    pred = prop_pred(z_mean).numpy()\n",
    "\n",
    "    preds.append(pred)\n",
    "\n",
    "preds = np.concatenate(preds, axis=0)#[0]\n",
    "trues = df_test[[\"qed\", \"SAS\", \"logP\"]].values\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "for i in range(3):\n",
    "    ax[i].scatter(trues[:, i], preds[:, i])\n",
    "    ax[i].set_xlabel(\"True\")\n",
    "    ax[i].set_ylabel(\"Predicted\")\n",
    "    ax[i].set_title(params[\"reg_prop_tasks\"][i])\n",
    "    # ensure y and x-axis limits are equal\n",
    "    ax[i].set_xlim(np.min(trues[:, i]) - 0.2, np.max(trues[:, i]) + 0.2)\n",
    "    ax[i].set_ylim(ax[i].get_xlim())\n",
    "    # add y=x line in red\n",
    "    ax[i].plot(np.linspace(ax[i].get_ylim()[0], ax[i].get_ylim()[1], 100), \n",
    "               np.linspace(ax[i].get_ylim()[0], ax[i].get_ylim()[1], 100), \"r-\", linewidth=2)\n",
    "    # adjust subplots\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "\n",
    "for i in range(len(df_train_subset)):\n",
    "    smiles_1 = df_train_subset.iloc[i][\"smiles\"]\n",
    "    X_1 = smiles_to_hot(smiles_1, params, canonize_smiles=True)\n",
    "    z_mean, enc_output = encoder(X_1)\n",
    "\n",
    "    pred = prop_pred(z_mean).numpy()\n",
    "    preds.append(pred)\n",
    "\n",
    "preds = np.concatenate(preds, axis=0)\n",
    "trues = df_train_subset[[\"qed\", \"SAS\", \"logP\"]].values\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "for i in range(3):\n",
    "    ax[i].scatter(trues[:, i], preds[:, i])\n",
    "    ax[i].set_xlabel(\"True\")\n",
    "    ax[i].set_ylabel(\"Predicted\")\n",
    "    ax[i].set_title(params[\"reg_prop_tasks\"][i])\n",
    "    # ensure y and x-axis limits are equal\n",
    "    ax[i].set_xlim(np.min(trues[:, i]) - 0.2, np.max(trues[:, i]) + 0.2)\n",
    "    ax[i].set_ylim(ax[i].get_xlim())\n",
    "    # add y=x line in red\n",
    "    ax[i].plot(np.linspace(ax[i].get_ylim()[0], ax[i].get_ylim()[1], 100), \n",
    "               np.linspace(ax[i].get_ylim()[0], ax[i].get_ylim()[1], 100), \"r-\", linewidth=2)\n",
    "    # adjust subplots\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode Keras encodings with Pytorch decoder - Test set\n",
    "z_means = []\n",
    "smiles_list = df_test[\"smiles\"].values\n",
    "\n",
    "for i in range(len(df_test)):\n",
    "    smiles = smiles_list[i]\n",
    "    input_onehot = smiles_to_hot(smiles, params, canonize_smiles=True)\n",
    "    z_mean, enc_output = encoder(input_onehot)\n",
    "    z_means.append(z_mean.numpy())\n",
    "\n",
    "z_means = np.concatenate(z_means, axis=0)\n",
    "z_means = torch.from_numpy(z_means).float()\n",
    "\n",
    "# Decoding with Pytorch decoder\n",
    "output_onehot = decoder_torch(z_means)\n",
    "# output_onehot_2 = decoder_torch_2(z_means)\n",
    "# output_onehot_3 = decoder_torch_3(z_means)\n",
    "output_onehot_4 = decoder_torch_4(z_means)\n",
    "\n",
    "output_onehot = output_onehot.detach().numpy()\n",
    "# output_onehot_2 = output_onehot_2.detach().numpy()\n",
    "# output_onehot_3 = output_onehot_3.detach().numpy()\n",
    "output_onehot_4 = output_onehot_4.detach().numpy()\n",
    "\n",
    "for i in range(10):\n",
    "    print('{:20s} : {}'.format('Input', smiles_list[i]))\n",
    "    print('{:20s} : {}'.format('Reconstruction 1', hot_to_smiles(output_onehot[i:i+1], indices_char)[0]))\n",
    "    # print('{:20s} : {}'.format('Reconstruction 2', hot_to_smiles(output_onehot_2[i:i+1], indices_char)[0]))\n",
    "    # print('{:20s} : {}'.format('Reconstruction 3', hot_to_smiles(output_onehot_3[i:i+1], indices_char)[0]))\n",
    "    print('{:20s} : {}'.format('Reconstruction 4', hot_to_smiles(output_onehot_4[i:i+1], indices_char)[0]))\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: something is wrong with the decoder:\n",
    "- activation layer: terminal GRU layer should have softmax at the new gate activation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating mock models of the encoder to identify differences in outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock Keras encoder\n",
    "from keras.layers import Input, Convolution1D, BatchNormalization, Flatten\n",
    "from keras.models import Model\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def mock_encoder_keras(params):\n",
    "    # K_params is dictionary of keras variables\n",
    "    x_in = Input(shape=(params[\"MAX_LEN\"], params[\"NCHARS\"]), name=\"input_molecule_smi\")\n",
    "\n",
    "    # Convolution layers\n",
    "    x = Convolution1D(\n",
    "        int(params[\"conv_dim_depth\"] * params[\"conv_d_growth_factor\"]),\n",
    "        int(params[\"conv_dim_width\"] * params[\"conv_w_growth_factor\"]),\n",
    "        activation=\"tanh\",\n",
    "        name=\"encoder_conv0\",\n",
    "    )(x_in)\n",
    "\n",
    "    if params[\"batchnorm_conv\"]:\n",
    "        x = BatchNormalization(axis=-1, name=\"encoder_norm0\")(x)\n",
    "\n",
    "    for j in range(1, params[\"conv_depth\"] - 1):\n",
    "        x = Convolution1D(\n",
    "            int(params[\"conv_dim_depth\"] * params[\"conv_d_growth_factor\"] ** (j)),\n",
    "            int(params[\"conv_dim_width\"] * params[\"conv_w_growth_factor\"] ** (j)),\n",
    "            activation=\"tanh\",\n",
    "            name=\"encoder_conv{}\".format(j),\n",
    "        )(x)\n",
    "        if params[\"batchnorm_conv\"]:\n",
    "            x = BatchNormalization(axis=-1, name=\"encoder_norm{}\".format(j))(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "\n",
    "    return Model(x_in, x, name=\"encoder\")\n",
    "\n",
    "\n",
    "# Mock Torch decoder\n",
    "class MockEncoderTorch(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super(MockEncoderTorch, self).__init__()\n",
    "        self.params = params\n",
    "\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        self.conv_norm_layers = nn.ModuleList()\n",
    "\n",
    "        # Convolution layers\n",
    "        in_channels = params[\"NCHARS\"]\n",
    "        out_channels = int(params[\"conv_dim_depth\"] * params[\"conv_d_growth_factor\"])\n",
    "        kernel_size = int(params[\"conv_dim_width\"] * params[\"conv_w_growth_factor\"])\n",
    "        conv_layer = nn.Conv1d(in_channels, out_channels, kernel_size)\n",
    "        self.conv_layers.append(conv_layer)\n",
    "        if params[\"batchnorm_conv\"]:\n",
    "            # norm_layer = nn.BatchNorm1d(out_channels)\n",
    "            norm_layer = CustomBatchNorm1d(out_channels)\n",
    "            self.conv_norm_layers.append(norm_layer)\n",
    "\n",
    "        in_channels = out_channels\n",
    "\n",
    "        for j in range(1, params[\"conv_depth\"] - 1):\n",
    "        # for j in range(1, 2):\n",
    "            out_channels = int(params[\"conv_dim_depth\"] * params[\"conv_d_growth_factor\"] ** j)\n",
    "            kernel_size = int(params[\"conv_dim_width\"] * params[\"conv_w_growth_factor\"] ** j)\n",
    "            conv_layer = nn.Conv1d(in_channels, out_channels, kernel_size)\n",
    "            self.conv_layers.append(conv_layer)\n",
    "\n",
    "            if params[\"batchnorm_conv\"]:\n",
    "                # norm_layer = nn.BatchNorm1d(out_channels)\n",
    "                norm_layer = CustomBatchNorm1d(out_channels)\n",
    "                self.conv_norm_layers.append(norm_layer)\n",
    "\n",
    "            in_channels = out_channels\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Middle layers\n",
    "        # if params[\"middle_layer\"] > 0:\n",
    "        #     self.middle_layers = nn.ModuleList()\n",
    "        #     self.dropout_layers = nn.ModuleList()\n",
    "        #     self.middle_norm_layers = nn.ModuleList()\n",
    "\n",
    "        #     # TODO: find a way to calculate in_features automatically\n",
    "        #     in_features = out_channels * 94\n",
    "\n",
    "            # for i in range(1, params[\"middle_layer\"] + 1):\n",
    "            #     out_features = int(params[\"hidden_dim\"] * params[\"hg_growth_factor\"] ** (params[\"middle_layer\"] - i))\n",
    "            #     middle_layer = nn.Linear(in_features, out_features)\n",
    "            #     self.middle_layers.append(middle_layer)\n",
    "\n",
    "            #     if params[\"dropout_rate_mid\"] > 0:\n",
    "            #         dropout_layer = nn.Dropout(params[\"dropout_rate_mid\"])\n",
    "            #         self.dropout_layers.append(dropout_layer)\n",
    "\n",
    "            #     if params[\"batchnorm_mid\"]:\n",
    "            #         norm_layer = nn.BatchNorm1d(out_features)\n",
    "            #         self.middle_norm_layers.append(norm_layer)\n",
    "\n",
    "            #     in_features = out_features\n",
    "\n",
    "        # # output has dim = hidden_dim = 100 (hyperparameters.py)\n",
    "        # self.z_mean = nn.Linear(in_features, params[\"hidden_dim\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolution layers\n",
    "        for i in range(len(self.conv_layers)):\n",
    "            x = self.conv_layers[i](x)\n",
    "            x = F.tanh(x)  # activation\n",
    "            # print(x.size())\n",
    "            if self.params[\"batchnorm_conv\"]:\n",
    "                x = self.conv_norm_layers[i](x)\n",
    "        # print(x.size())\n",
    "        x = x.transpose(2, 1)\n",
    "        x = self.flatten(x)\n",
    "        # print(\"x.size(): \", x.size())\n",
    "\n",
    "        # Middle layers\n",
    "        # if self.params[\"middle_layer\"] > 0:\n",
    "        #     for i in range(len(self.middle_layers)):\n",
    "        #         # print(\"TEST: \", i)\n",
    "        #         x = self.middle_layers[i](x)\n",
    "        #         x = F.tanh(x)\n",
    "        #         if self.params[\"dropout_rate_mid\"] > 0:\n",
    "        #             x = self.dropout_layers[i](x)\n",
    "        #         if self.params[\"batchnorm_mid\"]:\n",
    "        #             x = self.middle_norm_layers[i](x)\n",
    "\n",
    "        # output has dim = hidden_dim = 100 (hyperparameters.py)\n",
    "        # z_mean = self.z_mean(x)\n",
    "\n",
    "        # return both mean and last encoding layer for std dev sampling\n",
    "        # return z_mean, x\n",
    "        return x\n",
    "\n",
    "params_test = copy.deepcopy(params)\n",
    "# params_test[\"middle_layer\"] = 1\n",
    "mock_torch = MockEncoderTorch(params_test)\n",
    "mock_keras = mock_encoder_keras(params_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_keras.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(mock_torch, input_size=(35, 120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [weight.name for layer in encoder.layers for weight in layer.weights]\n",
    "weights = encoder.get_weights()\n",
    "for name, weight in zip(names, weights):\n",
    "    print(name, weight.shape)\n",
    "\n",
    "# Loading Keras weights into mock Keras encoder\n",
    "# mock_torch.conv_layers[0].weight.data = torch.from_numpy(weights[0].transpose(2, 1, 0))  # T\n",
    "# mock_torch.conv_layers[0].bias.data = torch.from_numpy(weights[1])\n",
    "mock_keras.get_layer('encoder_conv0').set_weights((weights[0], weights[1]))\n",
    "mock_keras.get_layer('encoder_norm0').set_weights((weights[2], weights[3], weights[4], weights[5]))\n",
    "mock_keras.get_layer('encoder_conv1').set_weights((weights[6], weights[7]))\n",
    "mock_keras.get_layer('encoder_norm1').set_weights((weights[8], weights[9], weights[10], weights[11]))\n",
    "mock_keras.get_layer('encoder_conv2').set_weights((weights[12], weights[13]))\n",
    "mock_keras.get_layer('encoder_norm2').set_weights((weights[14], weights[15], weights[16], weights[17]))\n",
    "\n",
    "# Loading Keras weights into PyTorch mock encoder\n",
    "mock_torch.conv_layers[0].weight.data = torch.from_numpy(weights[0].transpose(2, 1, 0))  # T\n",
    "mock_torch.conv_layers[0].bias.data = torch.from_numpy(weights[1])\n",
    "mock_torch.conv_norm_layers[0].weight.data = torch.from_numpy(weights[2])\n",
    "mock_torch.conv_norm_layers[0].bias.data = torch.from_numpy(weights[3])\n",
    "mock_torch.conv_norm_layers[0].running_mean.data = torch.from_numpy(weights[4])\n",
    "mock_torch.conv_norm_layers[0].running_var.data = torch.from_numpy(weights[5])\n",
    "\n",
    "mock_torch.conv_layers[1].weight.data = torch.from_numpy(weights[6].transpose(2, 1, 0))  # T\n",
    "mock_torch.conv_layers[1].bias.data = torch.from_numpy(weights[7])\n",
    "mock_torch.conv_norm_layers[1].weight.data = torch.from_numpy(weights[8])\n",
    "mock_torch.conv_norm_layers[1].bias.data = torch.from_numpy(weights[9])\n",
    "mock_torch.conv_norm_layers[1].running_mean.data = torch.from_numpy(weights[10])\n",
    "mock_torch.conv_norm_layers[1].running_var.data = torch.from_numpy(weights[11])\n",
    "\n",
    "mock_torch.conv_layers[2].weight.data = torch.from_numpy(weights[12].transpose(2, 1, 0))  # T\n",
    "mock_torch.conv_layers[2].bias.data = torch.from_numpy(weights[13])\n",
    "mock_torch.conv_norm_layers[2].weight.data = torch.from_numpy(weights[14])\n",
    "mock_torch.conv_norm_layers[2].bias.data = torch.from_numpy(weights[15])\n",
    "mock_torch.conv_norm_layers[2].running_mean.data = torch.from_numpy(weights[16])\n",
    "mock_torch.conv_norm_layers[2].running_var.data = torch.from_numpy(weights[17])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying that the weights were correctly loaded\n",
    "weights_mock = mock_keras.get_weights()\n",
    "# Kernel\n",
    "print(\"Keras: \", weights[0][:10, 0, 0])\n",
    "print(\"Mock: \", weights_mock[0][:10, 0, 0])\n",
    "# Bias\n",
    "print(\"Keras: \", weights[1][:10])\n",
    "print(\"Mock: \", weights_mock[1][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output with mock Keras encoder\n",
    "# create random input vector of size (1, 35, 120)\n",
    "x = np.random.rand(1, 120, 35)\n",
    "# encode with Keras\n",
    "output_keras = mock_keras.predict(x)\n",
    "# encode with PyTorch\n",
    "x = torch.from_numpy(x.transpose(0, 2, 1)).float()\n",
    "output_torch = mock_torch(x)\n",
    "output_torch = output_torch.detach().numpy()\n",
    "# output_torch = output_torch.transpose(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_keras.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_keras[0, 0, :10]\n",
    "output_keras[0, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_torch[0, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identical outputs with conv1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing outputs from full encoder\n",
    "\n",
    "# create random input vector of size (1, 35, 120)\n",
    "x = np.random.rand(1, 120, 35)\n",
    "# encode with Keras\n",
    "output_keras = encoder.predict(x)[0]\n",
    "# encode with PyTorch\n",
    "x = torch.from_numpy(x).float()\n",
    "output_torch = encoder_torch(x)[0]\n",
    "output_torch = output_torch.detach().numpy()\n",
    "# output_torch = output_torch.transpose(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_keras.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_keras[0, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_torch[0, :10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stability_vae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
